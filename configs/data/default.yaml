# Default Data Configuration

data:
  # Dataset parameters
  train_size: 0.9  # Fraction of data for training
  val_size: 0.1    # Fraction of data for validation
  sequence_length: 1024  # Length of input sequences
  stride: 512  # Stride for sliding window
  batch_size: 32  # Batch size for training
  num_workers: 4  # Number of workers for data loading
  pin_memory: true  # Use pinned memory for faster data loading
  
  # Tokenizer parameters
  tokenizer:
    type: character  # Character-level tokenization
    special_tokens:
      pad_token: " "
      unk_token: "?"
      bos_token: "^"
      eos_token: "$"
    
  # Data augmentation
  augmentation:
    enabled: false  # Whether to use data augmentation
    methods: []  # List of augmentation methods to use

# Default Data Configuration for ChatGoT

# Dataset
dataset:
  name: got_char  # Name of the dataset
  type: character  # character or token level
  split_ratio: 0.9  # Train/validation split ratio
  shuffle: true  # Whether to shuffle the data
  
# Processing
processing:
  lowercase: false  # Whether to lowercase the text
  remove_special_chars: false  # Whether to remove special characters
  min_frequency: 1  # Minimum frequency to include a character/token
  max_vocab_size: 256  # Maximum vocabulary size
  padding_token: 0  # Padding token ID
  unknown_token: 1  # Unknown token ID
  
# Dataloader
dataloader:
  num_workers: ${system.num_workers}  # Number of workers
  pin_memory: ${system.pin_memory}  # Whether to use pinned memory
  drop_last: false  # Whether to drop the last incomplete batch
  prefetch_factor: 2  # Number of samples loaded in advance by each worker
  
# Augmentation
augmentation:
  enabled: false  # Whether to use data augmentation
  techniques: []  # List of augmentation techniques to use
  
# Caching
caching:
  enabled: true  # Whether to cache processed data
  refresh: false  # Whether to force refresh the cache 