# Configuration for ChatGoT Small (14M parameters) - with gradient checkpointing enabled
model:
  architecture: gpt
  model_type: gpt_decoder  # Specify optimized decoder-only architecture
  vocab_size: 96          # Character-level vocabulary size
  d_model: 384            # Embedding dimension
  n_layers: 8             # Number of layers
  n_head: 6               # Number of attention heads 
  d_hid: 1536             # Hidden dimension in feed-forward layers
  dropout: 0.1            # Dropout rate
  attention_dropout: 0.1  # Dropout rate for attention
  layer_norm_eps: 1e-5    # Layer normalization epsilon
  activation: gelu        # Activation function
  bias: true              # Use bias in layers
  
  # Model initialization
  init_method: normal     # Initialization method
  init_range: 0.01        # Smaller initialization range for better stability
  
  # Positional encoding
  pos_encoding_type: learned  # Options: learned, sinusoidal
  max_seq_length: 256     # Sequence length

training:
  batch_size: 6           # Small batch size for memory efficiency
  learning_rate: 6e-4     # Higher learning rate
  weight_decay: 0.01      # Weight decay
  epochs: 1               # Number of epochs
  mixed_precision: false  # Disable mixed precision for isolation testing
  gradient_checkpointing: true  # ENABLED for testing
  accumulate_grad_batches: 2    # Use accumulation instead of large batch
  max_checkpoints_to_keep: 3    # Keep only 3 most recent checkpoints

  grad_clip: 1.0          # Gradient clipping threshold
  log_interval: 10        # Log every 10 batches
  sample_interval: 300    # Generate samples every 5 minutes

data:
  path: data/got/game_of_thrones.txt  # Data path
  test_split: 0.1         # Test split ratio

# Memory optimization settings
memory:
  optimize_memory: true
  empty_cache_freq: 100   # Empty cache every 100 batches
  cpu_offload: false      # Whether to offload optimizer states to CPU

# Additional parameters
n_positions: 256
embd_pdrop: 0.1
attn_pdrop: 0.1
initializer_range: 0.02
scale_attn_weights: true
use_cache: true 