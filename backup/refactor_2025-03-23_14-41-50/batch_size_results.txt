2025-03-23 14:19:25 - Logging to file: C:\Users\nimbu\Desktop\Code\AI\ChatGoT\batch_size_optimization.log
2025-03-23 14:19:25 - === LOGGING STARTED AT 2025-03-23 14:19:25 ===
2025-03-23 14:19:25 - Logger initialized with console and file output
2025-03-23 14:19:25 - Random seed set to 42 for reproducibility
2025-03-23 14:19:25 - Using GPU: NVIDIA GeForce GTX 1650 Ti
2025-03-23 14:19:25 - Number of GPUs: 1
2025-03-23 14:19:25 - CUDA Version: 11.8
2025-03-23 14:19:25 - GPU Memory: 4.00 GB (Free: 3.23 GB)
2025-03-23 14:19:25 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:19:25 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:19:25 - Vocabulary size: 89 characters
2025-03-23 14:19:25 - Created data loaders: 19268 training batches, 536 validation batches
2025-03-23 14:19:25 - GPU: NVIDIA GeForce GTX 1650 Ti with 4.00 GB memory
2025-03-23 14:19:26 - Model initialized with 768 dimensions, 85,192,793 parameters
2025-03-23 14:19:26 - Trainable parameters: 85,192,793
2025-03-23 14:19:26 - Estimated model size: 327.98MB
2025-03-23 14:19:26 - Created transformer model with 85,192,793 parameters
2025-03-23 14:19:26 - Model config: d_model=768, n_head=12, d_hid=3072, n_layers=12
2025-03-23 14:19:26 - Using standard GPT-2 Small architecture
2025-03-23 14:19:26 - Using memory-efficient attention implementation
2025-03-23 14:19:26 - Low GPU memory detected, testing conservative batch sizes
2025-03-23 14:19:26 - Testing batch sizes: [4, 8, 12, 16, 20, 24, 28, 32]
2025-03-23 14:19:26 - Testing batch size: 4
2025-03-23 14:19:28 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:19:28 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:19:28 - Vocabulary size: 89 characters
2025-03-23 14:19:28 - Created data loaders: 4817 training batches, 134 validation batches
2025-03-23 14:19:37 - Batch size 4 successful: 744.00 tokens/sec
2025-03-23 14:19:37 - Testing batch size: 8
2025-03-23 14:19:37 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:19:37 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:19:37 - Vocabulary size: 89 characters
2025-03-23 14:19:37 - Created data loaders: 2408 training batches, 67 validation batches
2025-03-23 14:19:53 - Batch size 8 successful: 748.38 tokens/sec
2025-03-23 14:19:53 - Testing batch size: 12
2025-03-23 14:19:53 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:19:53 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:19:53 - Vocabulary size: 89 characters
2025-03-23 14:19:53 - Created data loaders: 1605 training batches, 45 validation batches
2025-03-23 14:20:18 - Batch size 12 successful: 750.36 tokens/sec
2025-03-23 14:20:18 - Testing batch size: 16
2025-03-23 14:20:18 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:20:18 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:20:18 - Vocabulary size: 89 characters
2025-03-23 14:20:18 - Created data loaders: 1204 training batches, 34 validation batches
2025-03-23 14:20:51 - Batch size 16 successful: 750.69 tokens/sec
2025-03-23 14:20:51 - Testing batch size: 20
2025-03-23 14:20:51 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:20:51 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:20:51 - Vocabulary size: 89 characters
2025-03-23 14:20:51 - Created data loaders: 963 training batches, 27 validation batches
2025-03-23 14:21:32 - Batch size 20 successful: 750.86 tokens/sec
2025-03-23 14:21:32 - Testing batch size: 24
2025-03-23 14:21:32 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:21:32 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:21:32 - Vocabulary size: 89 characters
2025-03-23 14:21:32 - Created data loaders: 802 training batches, 23 validation batches
2025-03-23 14:22:21 - Batch size 24 successful: 750.49 tokens/sec
2025-03-23 14:22:21 - Testing batch size: 28
2025-03-23 14:22:21 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:22:21 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:22:21 - Vocabulary size: 89 characters
2025-03-23 14:22:21 - Created data loaders: 688 training batches, 20 validation batches
2025-03-23 14:23:19 - Batch size 28 successful: 750.54 tokens/sec
2025-03-23 14:23:19 - Testing batch size: 32
2025-03-23 14:23:19 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:23:19 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:23:19 - Vocabulary size: 89 characters
2025-03-23 14:23:19 - Created data loaders: 602 training batches, 17 validation batches
2025-03-23 14:24:26 - Batch size 32 successful: 730.40 tokens/sec
2025-03-23 14:24:26 - Testing additional batch sizes around best: [14, 18, 22, 26]
2025-03-23 14:24:26 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:24:26 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:24:26 - Vocabulary size: 89 characters
2025-03-23 14:24:26 - Created data loaders: 1376 training batches, 39 validation batches
2025-03-23 14:24:56 - Batch size 14 successful: 737.92 tokens/sec
2025-03-23 14:24:56 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:24:56 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:24:56 - Vocabulary size: 89 characters
2025-03-23 14:24:56 - Created data loaders: 1070 training batches, 30 validation batches
2025-03-23 14:25:33 - Batch size 18 successful: 735.97 tokens/sec
2025-03-23 14:25:33 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:25:34 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:25:34 - Vocabulary size: 89 characters
2025-03-23 14:25:34 - Created data loaders: 875 training batches, 25 validation batches
2025-03-23 14:26:20 - Batch size 22 successful: 736.19 tokens/sec
2025-03-23 14:26:20 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:26:20 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:26:20 - Vocabulary size: 89 characters
2025-03-23 14:26:20 - Created data loaders: 741 training batches, 21 validation batches
2025-03-23 14:27:14 - Batch size 26 successful: 738.01 tokens/sec
2025-03-23 14:27:14 - 
Batch size throughput results:
2025-03-23 14:27:14 -   Batch size 20: 750.86 tokens/sec
2025-03-23 14:27:14 -   Batch size 16: 750.69 tokens/sec
2025-03-23 14:27:14 -   Batch size 28: 750.54 tokens/sec
2025-03-23 14:27:14 -   Batch size 24: 750.49 tokens/sec
2025-03-23 14:27:14 -   Batch size 12: 750.36 tokens/sec
2025-03-23 14:27:14 -   Batch size 8: 748.38 tokens/sec
2025-03-23 14:27:14 -   Batch size 4: 744.00 tokens/sec
2025-03-23 14:27:14 -   Batch size 26: 738.01 tokens/sec
2025-03-23 14:27:14 -   Batch size 14: 737.92 tokens/sec
2025-03-23 14:27:14 -   Batch size 22: 736.19 tokens/sec
2025-03-23 14:27:14 -   Batch size 18: 735.97 tokens/sec
2025-03-23 14:27:14 -   Batch size 32: 730.40 tokens/sec
2025-03-23 14:27:14 - 
Optimal batch size: 20
2025-03-23 14:27:14 - Maximum throughput: 750.86 tokens/sec
2025-03-23 14:27:14 - 
Additional performance tips:
2025-03-23 14:27:14 -   - Try using --use_amp for faster training with minimal precision loss
2025-03-23 14:27:14 -   - Consider reducing model size with --d_model and --n_layers

=== OPTIMIZATION COMPLETE ===
Optimal batch size: 20
Use this batch size for maximum throughput with sequence length 1024

