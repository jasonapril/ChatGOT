2025-03-23 13:34:29 - Logging to file: C:\Users\nimbu\Desktop\Code\AI\ChatGoT\batch_size_optimization.log
2025-03-23 13:34:29 - === LOGGING STARTED AT 2025-03-23 13:34:29 ===
2025-03-23 13:34:29 - Logger initialized with console and file output
2025-03-23 13:34:31 - Random seed set to 42 for reproducibility
2025-03-23 13:34:31 - Using GPU: NVIDIA GeForce GTX 1650 Ti
2025-03-23 13:34:31 - Number of GPUs: 1
2025-03-23 13:34:31 - CUDA Version: 11.8
2025-03-23 13:34:31 - GPU Memory: 4.00 GB (Free: 3.23 GB)
2025-03-23 13:34:31 - Loading data from processed_data/got_char_data.pkl
2025-03-23 13:34:31 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 13:34:31 - Vocabulary size: 89 characters
2025-03-23 13:34:31 - Created data loaders: 19268 training batches, 536 validation batches
2025-03-23 13:34:31 - Model initialized with 768 dimensions, 85,192,793 parameters
2025-03-23 13:34:31 - Trainable parameters: 85,192,793
2025-03-23 13:34:31 - Estimated model size: 327.98MB
2025-03-23 13:34:32 - Created transformer model with 85,192,793 parameters
2025-03-23 13:34:32 - Model config: d_model=768, n_head=12, d_hid=3072, n_layers=12
2025-03-23 13:34:32 - Using standard GPT-2 Small architecture
2025-03-23 13:34:32 - Using memory-efficient attention implementation
2025-03-23 13:34:32 - Starting batch size optimization search: 1 to 256
2025-03-23 13:34:32 - Testing with sequence length: 1024
2025-03-23 13:34:32 - Testing batch size: 128
2025-03-23 13:34:35 - Error during batch size optimization: load_data() got an unexpected keyword argument 'sequence_length'
Traceback (most recent call last):
  File "C:\Users\nimbu\Desktop\Code\AI\ChatGoT\src\batch_size_finder.py", line 292, in <module>
    main()
    ~~~~^^
  File "C:\Users\nimbu\Desktop\Code\AI\ChatGoT\src\batch_size_finder.py", line 284, in main
    optimal_batch = find_optimal_batch_size(args)
  File "C:\Users\nimbu\Desktop\Code\AI\ChatGoT\src\batch_size_finder.py", line 208, in find_optimal_batch_size
    throughput, success = measure_throughput(
                          ~~~~~~~~~~~~~~~~~~^
        model=model,
        ^^^^^^^^^^^^
    ...<4 lines>...
        test_batches=args.test_batches
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\nimbu\Desktop\Code\AI\ChatGoT\src\batch_size_finder.py", line 81, in measure_throughput
    train_loader, _, _, _ = load_data(
                            ~~~~~~~~~^
        data_path=data_path,
        ^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        device_type=device.type
        ^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: load_data() got an unexpected keyword argument 'sequence_length'
2025-03-23 14:13:11 - Logging to file: C:\Users\nimbu\Desktop\Code\AI\ChatGoT\batch_size_optimization.log
2025-03-23 14:13:11 - === LOGGING STARTED AT 2025-03-23 14:13:11 ===
2025-03-23 14:13:11 - Logger initialized with console and file output
2025-03-23 14:13:12 - Random seed set to 42 for reproducibility
2025-03-23 14:13:12 - Using GPU: NVIDIA GeForce GTX 1650 Ti
2025-03-23 14:13:12 - Number of GPUs: 1
2025-03-23 14:13:12 - CUDA Version: 11.8
2025-03-23 14:13:12 - GPU Memory: 4.00 GB (Free: 3.23 GB)
2025-03-23 14:13:12 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:13:12 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:13:12 - Vocabulary size: 89 characters
2025-03-23 14:13:12 - Created data loaders: 19268 training batches, 536 validation batches
2025-03-23 14:13:12 - GPU: NVIDIA GeForce GTX 1650 Ti with 4.00 GB memory
2025-03-23 14:13:12 - Model initialized with 768 dimensions, 85,192,793 parameters
2025-03-23 14:13:12 - Trainable parameters: 85,192,793
2025-03-23 14:13:12 - Estimated model size: 327.98MB
2025-03-23 14:13:13 - Created transformer model with 85,192,793 parameters
2025-03-23 14:13:13 - Model config: d_model=768, n_head=12, d_hid=3072, n_layers=12
2025-03-23 14:13:13 - Using standard GPT-2 Small architecture
2025-03-23 14:13:13 - Using memory-efficient attention implementation
2025-03-23 14:13:13 - Low GPU memory detected, testing conservative batch sizes
2025-03-23 14:13:13 - Testing batch sizes: [4, 8, 12, 16, 20, 24, 28, 32]
2025-03-23 14:13:13 - Testing batch size: 4
2025-03-23 14:13:15 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:13:15 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:13:15 - Vocabulary size: 89 characters
2025-03-23 14:13:15 - Created data loaders: 4817 training batches, 134 validation batches
2025-03-23 14:13:23 - Batch size 4 successful: 751.12 tokens/sec
2025-03-23 14:13:23 - Testing batch size: 8
2025-03-23 14:13:23 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:13:23 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:13:23 - Vocabulary size: 89 characters
2025-03-23 14:13:23 - Created data loaders: 2408 training batches, 67 validation batches
2025-03-23 14:13:40 - Batch size 8 successful: 754.33 tokens/sec
2025-03-23 14:13:40 - Testing batch size: 12
2025-03-23 14:13:40 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:13:40 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:13:40 - Vocabulary size: 89 characters
2025-03-23 14:13:40 - Created data loaders: 1605 training batches, 45 validation batches
2025-03-23 14:14:04 - Batch size 12 successful: 753.06 tokens/sec
2025-03-23 14:14:04 - Testing batch size: 16
2025-03-23 14:14:04 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:14:04 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:14:04 - Vocabulary size: 89 characters
2025-03-23 14:14:04 - Created data loaders: 1204 training batches, 34 validation batches
2025-03-23 14:14:37 - Batch size 16 successful: 750.72 tokens/sec
2025-03-23 14:14:37 - Testing batch size: 20
2025-03-23 14:14:37 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:14:37 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:14:37 - Vocabulary size: 89 characters
2025-03-23 14:14:37 - Created data loaders: 963 training batches, 27 validation batches
2025-03-23 14:15:18 - Batch size 20 successful: 750.91 tokens/sec
2025-03-23 14:15:18 - Testing batch size: 24
2025-03-23 14:15:18 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:15:18 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:15:18 - Vocabulary size: 89 characters
2025-03-23 14:15:18 - Created data loaders: 802 training batches, 23 validation batches
2025-03-23 14:16:08 - Batch size 24 successful: 750.44 tokens/sec
2025-03-23 14:16:08 - Testing batch size: 28
2025-03-23 14:16:08 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:16:08 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:16:08 - Vocabulary size: 89 characters
2025-03-23 14:16:08 - Created data loaders: 688 training batches, 20 validation batches
2025-03-23 14:17:05 - Batch size 28 successful: 750.45 tokens/sec
2025-03-23 14:17:05 - Testing batch size: 32
2025-03-23 14:17:05 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:17:05 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:17:05 - Vocabulary size: 89 characters
2025-03-23 14:17:05 - Created data loaders: 602 training batches, 17 validation batches
2025-03-23 14:18:13 - Batch size 32 successful: 730.26 tokens/sec
2025-03-23 14:18:13 - Testing additional batch sizes around best: [2, 6, 10, 14]
2025-03-23 14:18:13 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:18:13 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:18:13 - Vocabulary size: 89 characters
2025-03-23 14:18:13 - Created data loaders: 9634 training batches, 268 validation batches
2025-03-23 14:18:17 - Batch size 2 successful: 688.14 tokens/sec
2025-03-23 14:18:17 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:18:17 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:18:17 - Vocabulary size: 89 characters
2025-03-23 14:18:17 - Created data loaders: 3211 training batches, 90 validation batches
2025-03-23 14:18:30 - Batch size 6 successful: 728.88 tokens/sec
2025-03-23 14:18:30 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:18:30 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:18:30 - Vocabulary size: 89 characters
2025-03-23 14:18:30 - Created data loaders: 1926 training batches, 54 validation batches
2025-03-23 14:18:51 - Batch size 10 successful: 738.68 tokens/sec
2025-03-23 14:18:51 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:18:51 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:18:51 - Vocabulary size: 89 characters
2025-03-23 14:18:51 - Created data loaders: 1376 training batches, 39 validation batches
2025-03-23 14:19:20 - Batch size 14 successful: 737.87 tokens/sec
2025-03-23 14:19:20 - 
Batch size throughput results:
2025-03-23 14:19:20 -   Batch size 8: 754.33 tokens/sec
2025-03-23 14:19:20 -   Batch size 12: 753.06 tokens/sec
2025-03-23 14:19:20 -   Batch size 4: 751.12 tokens/sec
2025-03-23 14:19:20 -   Batch size 20: 750.91 tokens/sec
2025-03-23 14:19:20 -   Batch size 16: 750.72 tokens/sec
2025-03-23 14:19:20 -   Batch size 28: 750.45 tokens/sec
2025-03-23 14:19:20 -   Batch size 24: 750.44 tokens/sec
2025-03-23 14:19:20 -   Batch size 10: 738.68 tokens/sec
2025-03-23 14:19:20 -   Batch size 14: 737.87 tokens/sec
2025-03-23 14:19:20 -   Batch size 32: 730.26 tokens/sec
2025-03-23 14:19:20 -   Batch size 6: 728.88 tokens/sec
2025-03-23 14:19:20 -   Batch size 2: 688.14 tokens/sec
2025-03-23 14:19:20 - 
Optimal batch size: 8
2025-03-23 14:19:20 - Maximum throughput: 754.33 tokens/sec
2025-03-23 14:19:20 - 
Additional performance tips:
2025-03-23 14:19:20 -   - Try using --use_amp for faster training with minimal precision loss
2025-03-23 14:19:20 -   - Consider reducing model size with --d_model and --n_layers
2025-03-23 14:19:25 - Logging to file: C:\Users\nimbu\Desktop\Code\AI\ChatGoT\batch_size_optimization.log
2025-03-23 14:19:25 - === LOGGING STARTED AT 2025-03-23 14:19:25 ===
2025-03-23 14:19:25 - Logger initialized with console and file output
2025-03-23 14:19:25 - Random seed set to 42 for reproducibility
2025-03-23 14:19:25 - Using GPU: NVIDIA GeForce GTX 1650 Ti
2025-03-23 14:19:25 - Number of GPUs: 1
2025-03-23 14:19:25 - CUDA Version: 11.8
2025-03-23 14:19:25 - GPU Memory: 4.00 GB (Free: 3.23 GB)
2025-03-23 14:19:25 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:19:25 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:19:25 - Vocabulary size: 89 characters
2025-03-23 14:19:25 - Created data loaders: 19268 training batches, 536 validation batches
2025-03-23 14:19:25 - GPU: NVIDIA GeForce GTX 1650 Ti with 4.00 GB memory
2025-03-23 14:19:26 - Model initialized with 768 dimensions, 85,192,793 parameters
2025-03-23 14:19:26 - Trainable parameters: 85,192,793
2025-03-23 14:19:26 - Estimated model size: 327.98MB
2025-03-23 14:19:26 - Created transformer model with 85,192,793 parameters
2025-03-23 14:19:26 - Model config: d_model=768, n_head=12, d_hid=3072, n_layers=12
2025-03-23 14:19:26 - Using standard GPT-2 Small architecture
2025-03-23 14:19:26 - Using memory-efficient attention implementation
2025-03-23 14:19:26 - Low GPU memory detected, testing conservative batch sizes
2025-03-23 14:19:26 - Testing batch sizes: [4, 8, 12, 16, 20, 24, 28, 32]
2025-03-23 14:19:26 - Testing batch size: 4
2025-03-23 14:19:28 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:19:28 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:19:28 - Vocabulary size: 89 characters
2025-03-23 14:19:28 - Created data loaders: 4817 training batches, 134 validation batches
2025-03-23 14:19:37 - Batch size 4 successful: 744.00 tokens/sec
2025-03-23 14:19:37 - Testing batch size: 8
2025-03-23 14:19:37 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:19:37 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:19:37 - Vocabulary size: 89 characters
2025-03-23 14:19:37 - Created data loaders: 2408 training batches, 67 validation batches
2025-03-23 14:19:53 - Batch size 8 successful: 748.38 tokens/sec
2025-03-23 14:19:53 - Testing batch size: 12
2025-03-23 14:19:53 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:19:53 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:19:53 - Vocabulary size: 89 characters
2025-03-23 14:19:53 - Created data loaders: 1605 training batches, 45 validation batches
2025-03-23 14:20:18 - Batch size 12 successful: 750.36 tokens/sec
2025-03-23 14:20:18 - Testing batch size: 16
2025-03-23 14:20:18 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:20:18 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:20:18 - Vocabulary size: 89 characters
2025-03-23 14:20:18 - Created data loaders: 1204 training batches, 34 validation batches
2025-03-23 14:20:51 - Batch size 16 successful: 750.69 tokens/sec
2025-03-23 14:20:51 - Testing batch size: 20
2025-03-23 14:20:51 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:20:51 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:20:51 - Vocabulary size: 89 characters
2025-03-23 14:20:51 - Created data loaders: 963 training batches, 27 validation batches
2025-03-23 14:21:32 - Batch size 20 successful: 750.86 tokens/sec
2025-03-23 14:21:32 - Testing batch size: 24
2025-03-23 14:21:32 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:21:32 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:21:32 - Vocabulary size: 89 characters
2025-03-23 14:21:32 - Created data loaders: 802 training batches, 23 validation batches
2025-03-23 14:22:21 - Batch size 24 successful: 750.49 tokens/sec
2025-03-23 14:22:21 - Testing batch size: 28
2025-03-23 14:22:21 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:22:21 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:22:21 - Vocabulary size: 89 characters
2025-03-23 14:22:21 - Created data loaders: 688 training batches, 20 validation batches
2025-03-23 14:23:19 - Batch size 28 successful: 750.54 tokens/sec
2025-03-23 14:23:19 - Testing batch size: 32
2025-03-23 14:23:19 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:23:19 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:23:19 - Vocabulary size: 89 characters
2025-03-23 14:23:19 - Created data loaders: 602 training batches, 17 validation batches
2025-03-23 14:24:26 - Batch size 32 successful: 730.40 tokens/sec
2025-03-23 14:24:26 - Testing additional batch sizes around best: [14, 18, 22, 26]
2025-03-23 14:24:26 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:24:26 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:24:26 - Vocabulary size: 89 characters
2025-03-23 14:24:26 - Created data loaders: 1376 training batches, 39 validation batches
2025-03-23 14:24:56 - Batch size 14 successful: 737.92 tokens/sec
2025-03-23 14:24:56 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:24:56 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:24:56 - Vocabulary size: 89 characters
2025-03-23 14:24:56 - Created data loaders: 1070 training batches, 30 validation batches
2025-03-23 14:25:33 - Batch size 18 successful: 735.97 tokens/sec
2025-03-23 14:25:33 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:25:34 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:25:34 - Vocabulary size: 89 characters
2025-03-23 14:25:34 - Created data loaders: 875 training batches, 25 validation batches
2025-03-23 14:26:20 - Batch size 22 successful: 736.19 tokens/sec
2025-03-23 14:26:20 - Loading data from processed_data/got_char_data.pkl
2025-03-23 14:26:20 - Data loaded: 19268 training sequences, 2141 validation sequences
2025-03-23 14:26:20 - Vocabulary size: 89 characters
2025-03-23 14:26:20 - Created data loaders: 741 training batches, 21 validation batches
2025-03-23 14:27:14 - Batch size 26 successful: 738.01 tokens/sec
2025-03-23 14:27:14 - 
Batch size throughput results:
2025-03-23 14:27:14 -   Batch size 20: 750.86 tokens/sec
2025-03-23 14:27:14 -   Batch size 16: 750.69 tokens/sec
2025-03-23 14:27:14 -   Batch size 28: 750.54 tokens/sec
2025-03-23 14:27:14 -   Batch size 24: 750.49 tokens/sec
2025-03-23 14:27:14 -   Batch size 12: 750.36 tokens/sec
2025-03-23 14:27:14 -   Batch size 8: 748.38 tokens/sec
2025-03-23 14:27:14 -   Batch size 4: 744.00 tokens/sec
2025-03-23 14:27:14 -   Batch size 26: 738.01 tokens/sec
2025-03-23 14:27:14 -   Batch size 14: 737.92 tokens/sec
2025-03-23 14:27:14 -   Batch size 22: 736.19 tokens/sec
2025-03-23 14:27:14 -   Batch size 18: 735.97 tokens/sec
2025-03-23 14:27:14 -   Batch size 32: 730.40 tokens/sec
2025-03-23 14:27:14 - 
Optimal batch size: 20
2025-03-23 14:27:14 - Maximum throughput: 750.86 tokens/sec
2025-03-23 14:27:14 - 
Additional performance tips:
2025-03-23 14:27:14 -   - Try using --use_amp for faster training with minimal precision loss
2025-03-23 14:27:14 -   - Consider reducing model size with --d_model and --n_layers
